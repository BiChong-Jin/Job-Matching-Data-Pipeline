# Job Matching Data Pipe Line

An event-driven analytics pipeline built on BigQuery and dbt.
Raw job-matching user events are ingested into a raw layer, transformed into
canonical deduplicated events, and further aggregated into business-facing
metrics such as funnels, ranking quality, and A/B test results.

The project demonstrates warehouse-centric data pipeline design,
incremental transformations, and data quality testing.

## High Level pipeline diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Job Matching Product â”‚
â”‚ (Web / Mobile / Backend) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â”‚ user events
              â”‚ (search, impression, click, apply)
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Batch Event Generator â”‚
â”‚ (Python / Backend Logs) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â”‚ NDJSON files
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸŸ¤ BigQuery â€“ Raw Events (Bronze) â”‚
â”‚ job_matching_bronze.events_raw â”‚
â”‚ - append-only â”‚
â”‚ - duplicates allowed â”‚
â”‚ - ingestion-time partitioned â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â”‚ dbt (silver models)
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âšª BigQuery â€“ Canonical Events (Silver) â”‚
â”‚ job_matching_silver.events â”‚
â”‚ - deduplicated â”‚
â”‚ - validated schema â”‚
â”‚ - event-time partitioned â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â”‚ dbt (gold models)
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸŸ¡ BigQuery â€“ Analytics Tables (Gold) â”‚
â”‚ - funnel_daily â”‚
â”‚ - ranking_metrics_daily â”‚
â”‚ - ab_metrics_daily â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚                 â”‚
      â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Dashboards â”‚ â”‚ Analysis / ML â”‚
â”‚ (PMs) â”‚ â”‚ (Analysts, Eng) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Time based workflow

```
T0 (all day)
â””â”€ Users interact with job search & ranking

T1 (nightly)
â””â”€ Batch job writes raw events
   â†’ job_matching_bronze.events_raw

T2 (after ingestion)
â””â”€ dbt run --select silver
   â†’ job_matching_silver.events

T3 (after silver)
â””â”€ dbt run --select gold
   â†’ job_matching_gold.*

T4 (morning)
â””â”€ PMs / engineers read dashboards & metrics
```

## Challenges & Key Learnings

1. BigQuery Streaming Insert Restriction (Free Tier)

Problem

Initial ingestion used BigQuery streaming inserts via the Python client. This failed due to free-tier restrictions that disallow streaming inserts.

Solution

Switched to a batch-oriented ingestion approach:

- Generated NDJSON files locally
- Loaded data using BigQuery load jobs programmatically
- Preserved replayability and cost efficiency

Learning
Batch load jobs are often preferable for reliability, cost control, and reprocessing, and are widely used in production systems.

2. dbt Profile and Schema Configuration Pitfalls

Problem

dbt generated unexpected dataset names (e.g. concatenated schemas) due to interaction between dataset in profiles.yml and +schema model configurations.

Solution

- Set a neutral dataset (dbt) in profiles.yml
- Controlled output datasets explicitly using +schema per model group (silver, gold)
- Cleaned dbt artifacts and recompiled models

Learning

In dbt-bigquery, the profile dataset and model schema configuration interact closely; clear separation avoids naming ambiguity.
